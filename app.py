import os
import re
import json
import time
import asyncio
from typing import Any, Dict, List, Optional, Tuple

import httpx
from fastapi import FastAPI, Header, Request, HTTPException
from pydantic import BaseModel

app = FastAPI()

GITLAB_URL = os.environ["GITLAB_URL"].rstrip("/")
GITLAB_TOKEN = os.environ["GITLAB_TOKEN"]
WEBHOOK_SECRET = os.environ["WEBHOOK_SECRET"]

# Anthropic / Claude Opus 4.5 via Messages API
ANTHROPIC_API_KEY = os.environ["OPUS_API_KEY"]  # –æ—Å—Ç–∞–≤–∏–º –∏–º—è –ø–µ—Ä–µ–º–µ–Ω–Ω–æ–π –∫–∞–∫ –±—ã–ª–æ
ANTHROPIC_API_URL = os.getenv("OPUS_API_URL", "https://api.anthropic.com/v1/messages")
ANTHROPIC_VERSION = os.getenv("ANTHROPIC_VERSION", "2023-06-01")
OPUS_MODEL = os.getenv("OPUS_MODEL", "claude-opus-4-5")
MAX_TOKENS = int(os.getenv("MAX_TOKENS", "35840"))

MAX_DIFF_CHARS = int(os.getenv("MAX_DIFF_CHARS", "20000"))
REQUEST_TIMEOUT = float(os.getenv("REQUEST_TIMEOUT", "60"))
SEM = asyncio.Semaphore(int(os.getenv("CONCURRENCY", "2")))

# –ö—ç—à –æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã—Ö SHA (project_id:mr_iid:sha -> timestamp)
PROCESSED_COMMITS: Dict[str, float] = {}
CACHE_TTL = 3600  # 1 —á–∞—Å


def gl_headers() -> Dict[str, str]:
    return {"PRIVATE-TOKEN": GITLAB_TOKEN}


class ReviewItem(BaseModel):
    path: str
    line: int
    severity: str = "medium"
    comment: str


def extract_project_id(payload: Dict[str, Any]) -> int:
    proj = payload.get("project") or {}
    pid = proj.get("id")
    if pid is None:
        raise ValueError("No project.id in payload")
    return int(pid)


def extract_mr_iid(payload: Dict[str, Any]) -> int:
    obj = payload.get("object_attributes") or {}
    iid = obj.get("iid")
    if iid is None:
        raise ValueError("No object_attributes.iid in payload")
    return int(iid)


async def gitlab_get(client: httpx.AsyncClient, path: str) -> Any:
    url = f"{GITLAB_URL}{path}"
    r = await client.get(url, headers=gl_headers(), timeout=REQUEST_TIMEOUT)
    r.raise_for_status()
    return r.json()


async def gitlab_post(client: httpx.AsyncClient, path: str, json_body: Dict[str, Any]) -> Any:
    url = f"{GITLAB_URL}{path}"
    r = await client.post(url, headers=gl_headers(), json=json_body, timeout=REQUEST_TIMEOUT)
    r.raise_for_status()
    return r.json()


async def get_existing_discussions(
    client: httpx.AsyncClient, project_id: int, mr_iid: int
) -> List[Dict[str, Any]]:
    """–ü–æ–ª—É—á–∏—Ç—å –≤—Å–µ —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–µ discussions –¥–ª—è MR"""
    discussions = await gitlab_get(
        client, f"/api/v4/projects/{project_id}/merge_requests/{mr_iid}/discussions"
    )
    return discussions or []


async def get_mr_diff_refs_and_changes(
    client: httpx.AsyncClient, project_id: int, mr_iid: int
) -> Tuple[Dict[str, str], List[Dict[str, Any]]]:
    mr = await gitlab_get(client, f"/api/v4/projects/{project_id}/merge_requests/{mr_iid}")
    diff_refs = mr.get("diff_refs") or {}
    changes = await gitlab_get(client, f"/api/v4/projects/{project_id}/merge_requests/{mr_iid}/changes")
    files = changes.get("changes") or []
    return diff_refs, files


async def get_commit_diff(
    client: httpx.AsyncClient, project_id: int, commit_sha: str
) -> List[Dict[str, Any]]:
    """–ü–æ–ª—É—á–∏—Ç—å diff —Ç–æ–ª—å–∫–æ –¥–ª—è –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–≥–æ –∫–æ–º–º–∏—Ç–∞"""
    commit = await gitlab_get(client, f"/api/v4/projects/{project_id}/repository/commits/{commit_sha}")
    diffs = await gitlab_get(client, f"/api/v4/projects/{project_id}/repository/commits/{commit_sha}/diff")
    return diffs or []


def build_diff_text(files: List[Dict[str, Any]]) -> str:
    parts: List[str] = []
    for f in files:
        new_path = f.get("new_path") or f.get("old_path") or "unknown"
        diff = f.get("diff") or ""
        if not diff:
            continue
        parts.append(f"FILE: {new_path}\n{diff}")
    return ("\n\n".join(parts))[:MAX_DIFF_CHARS]


def review_instructions(diff_text: str) -> str:
    # –í–∞–∂–Ω–æ: –ø—Ä–æ—Å–∏–º –°–¢–†–û–ì–û JSON –º–∞—Å—Å–∏–≤, –±–µ–∑ markdown
    return f"""
–¢—ã ‚Äî senior software engineer. –ü—Ä–æ–≤–µ–¥–∏ code review —Ç–æ–ª—å–∫–æ –ø–æ –∏–∑–º–µ–Ω–µ–Ω–∏—è–º –≤ diff.

–í–µ—Ä–Ω–∏ –°–¢–†–û–ì–û JSON –º–∞—Å—Å–∏–≤ (–±–µ–∑ markdown, –±–µ–∑ –ø–æ—è—Å–Ω–µ–Ω–∏–π).
–§–æ—Ä–º–∞—Ç –∫–∞–∂–¥–æ–≥–æ —ç–ª–µ–º–µ–Ω—Ç–∞:
{{
  "path": "relative/file/path",
  "line": <–Ω–æ–º–µ—Ä —Å—Ç—Ä–æ–∫–∏ –í –ù–û–í–û–ú —Ñ–∞–π–ª–µ>,
  "severity": "low|medium|high",
  "comment": "–∫—Ä–∞—Ç–∫–∏–π –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–π"
}}

–ü—Ä–∞–≤–∏–ª–∞:
- –ò—Å–ø–æ–ª—å–∑—É–π —Ç–æ–ª—å–∫–æ —Å—Ç—Ä–æ–∫–∏, –∫–æ—Ç–æ—Ä—ã–µ —Ä–µ–∞–ª—å–Ω–æ —Å—É—â–µ—Å—Ç–≤—É—é—Ç –≤ –ù–û–í–û–ô –≤–µ—Ä—Å–∏–∏ —Ñ–∞–π–ª–∞.
- –ï—Å–ª–∏ –Ω–µ —É–≤–µ—Ä–µ–Ω –≤ –Ω–æ–º–µ—Ä–µ —Å—Ç—Ä–æ–∫–∏ ‚Äî –ù–ï –¥–æ–±–∞–≤–ª—è–π —ç–ª–µ–º–µ–Ω—Ç.
- –ù–µ –¥—É–±–ª–∏—Ä—É–π –æ–¥–Ω–æ –∏ —Ç–æ –∂–µ –∑–∞–º–µ—á–∞–Ω–∏–µ.

DIFF:
{diff_text}
""".strip()


async def call_opus_anthropic(client: httpx.AsyncClient, diff_text: str) -> List[ReviewItem]:
    payload = {
        "model": OPUS_MODEL,
        "max_tokens": MAX_TOKENS,
        "messages": [{"role": "user", "content": review_instructions(diff_text)}],
    }
    headers = {
        "x-api-key": ANTHROPIC_API_KEY,
        "anthropic-version": ANTHROPIC_VERSION,
        "content-type": "application/json",
    }

    r = await client.post(ANTHROPIC_API_URL, headers=headers, json=payload, timeout=REQUEST_TIMEOUT)
    r.raise_for_status()
    data = r.json()

    # Anthropic Messages API: content = [{"type":"text","text":"..."}]
    blocks = data.get("content") or []
    text = ""
    for b in blocks:
        if b.get("type") == "text":
            text += b.get("text", "")
    text = text.strip()

    # –î–æ—Å—Ç–∞—ë–º JSON –º–∞—Å—Å–∏–≤ (–Ω–∞ —Å–ª—É—á–∞–π –µ—Å–ª–∏ –º–æ–¥–µ–ª—å –¥–æ–±–∞–≤–∏—Ç —á—Ç–æ-—Ç–æ –≤–æ–∫—Ä—É–≥)
    m = re.search(r"\[.*\]", text, flags=re.S)
    if m:
        text = m.group(0)

    raw = json.loads(text)
    items: List[ReviewItem] = []
    for it in raw:
        try:
            items.append(ReviewItem(**it))
        except Exception:
            continue
    return items


def line_in_diff(file_diff: str, target_new_line: int) -> bool:
    # Hunk header: @@ -a,b +c,d @@
    for h in re.finditer(r"@@\s*-\d+(?:,\d+)?\s+\+(\d+)(?:,(\d+))?\s*@@", file_diff):
        start = int(h.group(1))
        count = int(h.group(2) or "1")
        if start <= target_new_line <= (start + max(count - 1, 0)):
            return True
    return False


def is_duplicate_comment(
    existing_discussions: List[Dict[str, Any]], path: str, line: int, comment: str
) -> bool:
    """–ü—Ä–æ–≤–µ—Ä–∏—Ç—å, —Å—É—â–µ—Å—Ç–≤—É–µ—Ç –ª–∏ —É–∂–µ –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–π –Ω–∞ —ç—Ç–æ–π –ø–æ–∑–∏—Ü–∏–∏"""
    # –ù–æ—Ä–º–∞–ª–∏–∑—É–µ–º –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–π –¥–ª—è —Å—Ä–∞–≤–Ω–µ–Ω–∏—è (—É–±–∏—Ä–∞–µ–º –ª–∏—à–Ω–∏–µ –ø—Ä–æ–±–µ–ª—ã)
    normalized_comment = " ".join(comment.split())
    
    for disc in existing_discussions:
        notes = disc.get("notes") or []
        for note in notes:
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ —ç—Ç–æ AI –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–π
            body = note.get("body") or ""
            if not body.startswith("ü§ñ"):
                continue
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –ø–æ–∑–∏—Ü–∏—é
            position = note.get("position")
            if not position:
                continue
                
            note_path = position.get("new_path") or position.get("old_path")
            note_line = position.get("new_line") or position.get("old_line")
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å–æ–≤–ø–∞–¥–µ–Ω–∏–µ —Ñ–∞–π–ª–∞ –∏ —Å—Ç—Ä–æ–∫–∏
            if note_path != path or note_line != line:
                continue
            
            # –ù–æ—Ä–º–∞–ª–∏–∑—É–µ–º body –¥–ª—è —Å—Ä–∞–≤–Ω–µ–Ω–∏—è
            normalized_body = " ".join(body.split())
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ —Ç–µ–∫—Å—Ç –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏—è —Å–æ–≤–ø–∞–¥–∞–µ—Ç (–Ω–µ –ø—Ä–æ—Å—Ç–æ —Å–æ–¥–µ—Ä–∂–∏—Ç—Å—è)
            if normalized_comment in normalized_body:
                return True
    return False


async def post_inline_discussion(
    client: httpx.AsyncClient,
    project_id: int,
    mr_iid: int,
    diff_refs: Dict[str, str],
    item: ReviewItem,
    existing_discussions: List[Dict[str, Any]],
) -> bool:
    base_sha = diff_refs.get("base_sha")
    start_sha = diff_refs.get("start_sha")
    head_sha = diff_refs.get("head_sha")
    if not (base_sha and start_sha and head_sha):
        return False

    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞ –¥—É–±–ª–∏–∫–∞—Ç—ã
    if is_duplicate_comment(existing_discussions, item.path, item.line, item.comment):
        return True  # –°—á–∏—Ç–∞–µ–º —É—Å–ø–µ—à–Ω—ã–º, —Ç.–∫. –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–π —É–∂–µ –µ—Å—Ç—å

    body = {
        "body": f"ü§ñ **AI review ({item.severity})**: {item.comment}",
        "position": {
            "position_type": "text",
            "base_sha": base_sha,
            "start_sha": start_sha,
            "head_sha": head_sha,
            "new_path": item.path,
            "new_line": item.line,
        },
    }
    try:
        await gitlab_post(
            client, f"/api/v4/projects/{project_id}/merge_requests/{mr_iid}/discussions", body
        )
        return True
    except Exception:
        return False


async def post_general_note(client: httpx.AsyncClient, project_id: int, mr_iid: int, text: str) -> None:
    await gitlab_post(client, f"/api/v4/projects/{project_id}/merge_requests/{mr_iid}/notes", {"body": text})


def cleanup_old_cache_entries() -> None:
    """–û—á–∏—Å—Ç–∏—Ç—å —Å—Ç–∞—Ä—ã–µ –∑–∞–ø–∏—Å–∏ –∏–∑ –∫—ç—à–∞"""
    current_time = time.time()
    keys_to_remove = [k for k, v in PROCESSED_COMMITS.items() if current_time - v > CACHE_TTL]
    for k in keys_to_remove:
        PROCESSED_COMMITS.pop(k, None)


def is_commit_processed(project_id: int, mr_iid: int, sha: str) -> bool:
    """–ü—Ä–æ–≤–µ—Ä–∏—Ç—å, –±—ã–ª –ª–∏ —É–∂–µ –æ–±—Ä–∞–±–æ—Ç–∞–Ω —ç—Ç–æ—Ç –∫–æ–º–º–∏—Ç"""
    cleanup_old_cache_entries()
    key = f"{project_id}:{mr_iid}:{sha}"
    return key in PROCESSED_COMMITS


def mark_commit_processed(project_id: int, mr_iid: int, sha: str) -> None:
    """–û—Ç–º–µ—Ç–∏—Ç—å –∫–æ–º–º–∏—Ç –∫–∞–∫ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã–π"""
    key = f"{project_id}:{mr_iid}:{sha}"
    PROCESSED_COMMITS[key] = time.time()


async def process_merge_request(payload: Dict[str, Any]) -> None:
    async with SEM:
        try:
            project_id = extract_project_id(payload)
            mr_iid = extract_mr_iid(payload)
        except Exception as e:
            return

        async with httpx.AsyncClient() as client:
            # –ü–æ–ª—É—á–∞–µ–º diff_refs –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏ SHA
            diff_refs, files = await get_mr_diff_refs_and_changes(client, project_id, mr_iid)
            head_sha = diff_refs.get("head_sha", "")
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –Ω–µ –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞–ª–∏ –ª–∏ –º—ã —É–∂–µ —ç—Ç–æ—Ç –∫–æ–º–º–∏—Ç
            if head_sha and is_commit_processed(project_id, mr_iid, head_sha):
                return  # –£–∂–µ –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞–ª–∏ —ç—Ç–æ—Ç –∫–æ–º–º–∏—Ç
            
            # –ü–æ–ª—É—á–∞–µ–º —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–µ discussions –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏ –¥—É–±–ª–∏–∫–∞—Ç–æ–≤
            existing_discussions = await get_existing_discussions(client, project_id, mr_iid)
            
            # –ü—ã—Ç–∞–µ–º—Å—è –ø–æ–ª—É—á–∏—Ç—å diff —Ç–æ–ª—å–∫–æ –ø–æ—Å–ª–µ–¥–Ω–µ–≥–æ –∫–æ–º–º–∏—Ç–∞
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –µ—Å—Ç—å –ª–∏ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ –ø–æ—Å–ª–µ–¥–Ω–µ–º –∫–æ–º–º–∏—Ç–µ –≤ payload
            last_commit = None
            obj_attrs = payload.get("object_attributes") or {}
            if obj_attrs.get("last_commit"):
                last_commit = obj_attrs["last_commit"].get("id")
            
            # –ï—Å–ª–∏ —ç—Ç–æ update –∏ –µ—Å—Ç—å last_commit, –∏—Å–ø–æ–ª—å–∑—É–µ–º —Ç–æ–ª—å–∫–æ –µ–≥–æ diff
            action = obj_attrs.get("action")
            if action == "update" and last_commit:
                try:
                    files = await get_commit_diff(client, project_id, last_commit)
                except Exception:
                    # –ï—Å–ª–∏ –Ω–µ –ø–æ–ª—É—á–∏–ª–æ—Å—å - –∏—Å–ø–æ–ª—å–∑—É–µ–º –≤–µ—Å—å MR diff
                    pass
            
            diff_text = build_diff_text(files)

            if not diff_text.strip():
                await post_general_note(client, project_id, mr_iid, "ü§ñ AI review: –∏–∑–º–µ–Ω–µ–Ω–∏–π –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ –Ω–µ—Ç.")
                if head_sha:
                    mark_commit_processed(project_id, mr_iid, head_sha)
                return

            try:
                items = await call_opus_anthropic(client, diff_text)
            except Exception as e:
                await post_general_note(client, project_id, mr_iid, f"ü§ñ AI review: –æ—à–∏–±–∫–∞ –≤—ã–∑–æ–≤–∞ –º–æ–¥–µ–ª–∏: `{e}`")
                if head_sha:
                    mark_commit_processed(project_id, mr_iid, head_sha)
                return

            diff_map = {}
            for f in files:
                p = f.get("new_path") or f.get("old_path") or ""
                d = f.get("diff") or ""
                if p:
                    diff_map[p] = d

            posted = 0
            fallback: List[str] = []

            for it in items[:20]:
                d = diff_map.get(it.path, "")
                if not d or not line_in_diff(d, it.line):
                    fallback.append(f"- `{it.path}:{it.line}` ({it.severity}) {it.comment}")
                    continue

                ok = await post_inline_discussion(
                    client, project_id, mr_iid, diff_refs, it, existing_discussions
                )
                if ok:
                    posted += 1
                else:
                    fallback.append(f"- `{it.path}:{it.line}` ({it.severity}) {it.comment}")

            if fallback:
                text = "ü§ñ **AI review (–Ω–µ —É–¥–∞–ª–æ—Å—å –ø—Ä–∏–≤—è–∑–∞—Ç—å inline):**\n" + "\n".join(fallback)
                await post_general_note(client, project_id, mr_iid, text)

            if posted == 0 and not fallback:
                await post_general_note(client, project_id, mr_iid, "ü§ñ AI review: –∫—Ä–∏—Ç–∏—á–Ω—ã—Ö –∑–∞–º–µ—á–∞–Ω–∏–π –Ω–µ –Ω–∞–π–¥–µ–Ω–æ.")
            
            # –û—Ç–º–µ—á–∞–µ–º –∫–æ–º–º–∏—Ç –∫–∞–∫ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã–π
            if head_sha:
                mark_commit_processed(project_id, mr_iid, head_sha)


@app.post("/ai-review")
async def ai_review_webhook(
    request: Request,
    x_gitlab_token: Optional[str] = Header(default=None, alias="X-Gitlab-Token"),
    x_gitlab_event: Optional[str] = Header(default=None, alias="X-Gitlab-Event"),
):
    if x_gitlab_token != WEBHOOK_SECRET:
        raise HTTPException(status_code=403, detail="Invalid webhook token")

    payload = await request.json()

    # Merge request hook
    event = x_gitlab_event or ""
    if "Merge Request Hook" not in event and payload.get("object_kind") != "merge_request":
        return {"ok": True, "ignored": True}

    attrs = payload.get("object_attributes") or {}
    action = attrs.get("action")
    if action not in ("open", "update", "reopen"):
        return {"ok": True, "ignored_action": action}

    asyncio.create_task(process_merge_request(payload))
    return {"ok": True}
